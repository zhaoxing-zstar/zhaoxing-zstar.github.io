<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>GRE Experience</title>
    <url>/2021/10/18/GRE-Experience/</url>
    <content><![CDATA[<p>在飞机上没什么事来写篇GRE的经验吧。。。<br>我总共考过两次GRE</p>
<ul>
<li>第一次：153+168+3.5</li>
<li>第二次：159+169+4.0</li>
</ul>
<p>GRE考试分为写作、Verbal、Quantitative三大部分。Verbal和Quantitative都是20个题，Verbal部分包括10个填空和10个阅读，时间为30min，Quantitative是20个数学题，考试时间35min，写作要写Issue和Argument两篇。<br>考试时顺序是：两篇写作+VQVQV  或 QVQVQ ， 据说写完写作那个1min等完是可以进入Q的加试，但我试了试好像并没有成功。虽然数学没有满分比较遗憾，我就主要说说用了哪些资料以及一些技巧吧，我提到的资料会放在最后的网盘里。</p>
<h4 id="I-单词"><a href="#I-单词" class="headerlink" title="I. 单词"></a>I. 单词</h4><p>单词绝对是GRE考试的重中之重，建议反复背3000词到差不多能认识80%。我背过的词有：</p>
<ol>
<li>GRE3000词（手机app）</li>
<li>六选二等价词（十分重要！！！）</li>
<li>数学词汇（做题得知道什么意思啊）<br>大概就这些，再就是做题时候注重积累。</li>
</ol>
<h4 id="II-填空"><a href="#II-填空" class="headerlink" title="II. 填空"></a>II. 填空</h4><p>填空可以说是全靠单词和逻辑了，基本的取正、取反；冒号、分号、逗号；转折：yet, but, however, nevertheless知道，剩下就是刷机经了。还有最好能回顾下错题加深印象，通过刷机经培养做题思维可能更重要，因为我第二次考几乎没遇到原题…<br>4. 填空机经1500题</p>
<h4 id="III-阅读"><a href="#III-阅读" class="headerlink" title="III. 阅读"></a>III. 阅读</h4><p>阅读我觉得理清句间和段落关系比较重要，读的时候可以尝试总结3s版本，把握整体结构，最后做题再定位去找细节。可能做多就有感觉了吧，我刷了有机经里的100多篇吧，正确率大概70%左右。做过GRE阅读就会体会到托福阅读多么简单了…<br>5. 阅读机经350题</p>
<h4 id="IV-数学"><a href="#IV-数学" class="headerlink" title="IV. 数学"></a>IV. 数学</h4><p>基本难度不会超过高中，主要就是细心，然后做做难题。考试时我会做两遍，从头到尾，再做回去，这样能检查一下。<br>6. 维夕数学难题<br>7. 张巍170难题3.0（一定要做）</p>
<h4 id="V-写作"><a href="#V-写作" class="headerlink" title="V.写作"></a>V.写作</h4><p>理工科的话写作基本到3.5就可以，黑皮书Issue和Argument分的每类下面都挑一篇细读一下，再自己练几篇基本就没什么问题了。<br>8. GRE写作高频题目及考点精析（黑皮书）</p>
<p>最后祝大家都能杀G成功！</p>
<p>链接：<a href="https://pan.baidu.com/s/1nln9Aby8cwr8hzv2aCvQpg">https://pan.baidu.com/s/1nln9Aby8cwr8hzv2aCvQpg</a><br>提取码：ixwe</p>
<p>还有两个一亩三分地上比较好的经验分享：<br><a href="https://www.1point3acres.com/bbs/thread-792086-1-1.html">https://www.1point3acres.com/bbs/thread-792086-1-1.html</a><br><a href="https://www.1point3acres.com/bbs/thread-797603-1-1.html">https://www.1point3acres.com/bbs/thread-797603-1-1.html</a></p>
]]></content>
      <categories>
        <category>Learn</category>
      </categories>
      <tags>
        <tag>English</tag>
        <tag>GRE</tag>
      </tags>
  </entry>
  <entry>
    <title>Change the default working directory of Jupyter Notebook</title>
    <url>/2021/02/03/Jupyter-Change-Dir/</url>
    <content><![CDATA[<p><strong>后来发现好像直接从那个directory下面打开<code>Jupyter Lab</code>就可以…</strong></p>
<h3 id="下载Anaconda3"><a href="#下载Anaconda3" class="headerlink" title="下载Anaconda3"></a>下载Anaconda3</h3><p>首先从官网下载Anaconda3的Individual Edition，下载好后打开Anaconda3 Prompt，输入:<br>jupyter notebook –generate-config:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jupyter notebook --generate-config</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="打开配置文件"><a href="#打开配置文件" class="headerlink" title="打开配置文件"></a>打开配置文件</h3><p>输入完后，会显示文件产生的路径，按路径找到jupyter_notebook_config.py，用txt或者pycharm打开，<br>按<code>ctrl+F</code>搜索notebook_dir，找到后填入想要设置的路径并保存（注意顺便Uncomment这一行，就是删掉前面的<code>#</code>号,加路径时最好前面加上<code>r</code>转义<br><img src="/images/jupyter/notebook_dir.png" alt="notebook_dir"></p>
<hr>
<h3 id="修改JupyterNotebook快捷方式的目标属性"><a href="#修改JupyterNotebook快捷方式的目标属性" class="headerlink" title="修改JupyterNotebook快捷方式的目标属性"></a>修改JupyterNotebook快捷方式的目标属性</h3><p>右击JupyterNotebook快捷方式，选择[属性]，删除[目标]属性中的[%USERPROFILE%]，点击[确定]</p>
<p><img src="/images/jupyter/change_prop.png" alt="change_prop"></p>
<p>修改完成，再打开Anaconda Prompt输入jupyter notebook打开工作路径就发生变化了。</p>
]]></content>
      <categories>
        <category>Settings</category>
      </categories>
      <tags>
        <tag>Jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title>Old Version Home Page Setup</title>
    <url>/2021/02/08/Page-Set-Up/</url>
    <content><![CDATA[<h3 id="安装Ruby"><a href="#安装Ruby" class="headerlink" title="安装Ruby"></a>安装Ruby</h3><p>Windows直接从这里下载<a href="https://rubyinstaller.org/">RubyInstaller</a>,下载后按照提示安装即可。\<br>打开Ruby Prompt输入：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#install bundle, jekyll</span></span><br><span class="line">gem install bundle jekyll</span><br><span class="line"></span><br><span class="line"><span class="comment">#cd to personal page directory</span></span><br><span class="line">bundle init \\</span><br><span class="line">bundle install \\</span><br><span class="line">bundle <span class="built_in">exec</span> jekyll server </span><br><span class="line">(or jekyll serve)</span><br><span class="line"></span><br><span class="line"><span class="comment">#the page generated locally will update as you make changes</span></span><br></pre></td></tr></table></figure>

<h3 id="NPM-amp-Hexo-Setup"><a href="#NPM-amp-Hexo-Setup" class="headerlink" title="NPM &amp; Hexo Setup"></a>NPM &amp; Hexo Setup</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt update \\</span><br><span class="line">sudo apt install nodejs \\</span><br><span class="line">sudo apt install npm \\</span><br><span class="line">node -v \\</span><br><span class="line">npm -v \\</span><br><span class="line">npm install -g hexo-cli \\</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;PATH=&quot;$PATH:./node_modules/.bin&quot;&#x27;</span> &gt;&gt; ~/.profile</span><br></pre></td></tr></table></figure>

<p>Ref: <a href="https://shen-yu.github.io/2019/ayer/">Ayer中文说明</a>. All modifications for this website should be done in <code>themes</code> folder, instead of <code>public</code> folder</p>
<h3 id="Git-Setup"><a href="#Git-Setup" class="headerlink" title="Git Setup"></a>Git Setup</h3><p>Git cheatsheet: <a href="https://education.github.com/git-cheat-sheet-education.pdf">cheatsheet</a> </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#clone from websit</span></span><br><span class="line">git <span class="built_in">clone</span> XXX.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># generate private &amp; public key</span></span><br><span class="line">ssh -t rsa -C <span class="string">&quot;email@XX.com&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># upload public key to github, test with:</span></span><br><span class="line">ssh git@github.com</span><br><span class="line"></span><br><span class="line"><span class="comment">#set up configs</span></span><br><span class="line">git config --global user.name <span class="string">&quot;name&quot;</span></span><br><span class="line">git config --global user.email <span class="string">&quot;email&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#handle proxy error</span></span><br><span class="line">git config --global --<span class="built_in">unset</span> http.proxy</span><br><span class="line">git config --global --<span class="built_in">unset</span> https.proxy</span><br><span class="line"></span><br><span class="line"><span class="comment">#make changes and submit</span></span><br><span class="line">git add .</span><br><span class="line">git commit -m <span class="string">&quot;message&quot;</span></span><br><span class="line">git add remote origin <span class="string">&quot;reop.git&quot;</span></span><br><span class="line">git psuh origin main</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Website</category>
      </categories>
      <tags>
        <tag>Home Page</tag>
        <tag>Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title>CS224n: Natural Language Processing with Deep Learning</title>
    <url>/2022/06/09/NLP-with-DL/</url>
    <content><![CDATA[<p>Click here hhhhh: <a href="https://zhaoxing-zstar.github.io/CS224n-Natural-Language-Processing-with-Deep-Learning/">https://zhaoxing-zstar.github.io/CS224n-Natural-Language-Processing-with-Deep-Learning/</a></p>
]]></content>
      <categories>
        <category>Learn</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Equations of Mathematical Physics Course Page</title>
    <url>/2021/03/05/mathematical-physics/</url>
    <content><![CDATA[<p>Click Here: <a href="https://zhaoxing-zstar.github.io/Equations-of-Mathematical-Physics/">Equations of Mathematical Physics</a></p>
]]></content>
      <categories>
        <category>Learn</category>
      </categories>
      <tags>
        <tag>mathematical physics</tag>
      </tags>
  </entry>
  <entry>
    <title>HFT_return</title>
    <url>/2023/07/02/HFT-return/</url>
    <content><![CDATA[<h1 id="How-and-When-are-High-Frequency-Stock-Returns-Predictable"><a href="#How-and-When-are-High-Frequency-Stock-Returns-Predictable" class="headerlink" title="How and When are High-Frequency Stock Returns Predictable?"></a>How and When are High-Frequency Stock Returns Predictable?</h1><ul>
<li>NBER Working Paper.</li>
</ul>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>低频和long horizon的return的可预测性不高且变化无常，高频收益的可预测性更加可靠，系统且较为集中。根据从trades和quotes data中确定的相关的预测变量， 研究了什么决定了不同股票的自身特点和市场环境的可预测性的差异。并计算预测能力随着数据时效性提高而改善的程度。最后，通过模拟能够提前获知不完美的订单流来检验能否影响后续return和duration的预测性， 这是高频交易者常常能够得到的look ahead information。</p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>作者发现几乎所有的利息在所有股票和较短的时段内都能够很强并且一致的被预测， 包括，短期内价格变动，方向，大小和动量，以及连续到达的orders和transcations之间的间隔，都可以被预测。低频可预测性的问题对于金融市场的有效性以及资产配置策略具有重要的意义。另一方面，高频可预测性的问题对于金融市场的设计、运营和监管的理论含义以及交易和执行策略的实践具有重要的影响。</p>
<p>过去15年各种高频交易公司所取得的丰厚且连续的收益仿佛验证了高频收益的可预测性，但学界对这方面的研究不如低频深入。在本论文中，除过量化数据中存在的可预测性以及消散速度，也试图确定哪些预测变量对下一笔交易和间隔最有信息量。文章使用了trade和quotes data, 使用的机器学习方法有LASSO, RF, NN，并且不同的方法对最终结论影响较小，未使用probabilistic or statistical方法的原因是<strong>发现从LOB的state和evolution的得到的变量对收益的预测效果不如从transcation record中得到的变量</strong>, 下面作者阐述了一些贡献，总结：</p>
<p>a. 使用的数据是S&amp;P 100 index Jan 2019 - Dec 2020的101只股票的transcations和quote data. 所有股票的out of sample可预测性在不同时段都存在。5秒的收益样本外$R^2$为10.5%， 下一单的方向准确率为$64%$,预测下来10笔交易的间隔，样本外$R^2$为$9.8%$, 以上都为median。 return和方向的预测，重要的predictor有order book imbalance, recent transcation imbalance,以及 past trade returns, 但从最近的trade volume得到的统计量对duration的预测更有效。这里主要是作者有构建一些predictor，并观察feature importance得出的结论。</p>
<p>b. return和trade方向对名义股价较小，流动性较差，波动性较小，与总体市值相关性较小的股票更好预测</p>
<p>c. 收益的可预测性5min内就会刷见到0，大概是2000次交易或是2000手交易量</p>
<p>d. latency或是数据的delay会显著降低预测的准确性</p>
<p>e. “look ahead” at the incoming flow的能力，即使是一个不完美的方向预测，会将5min return预测的$R^2$从$14.0%$提升至$27.1%$, price方向的准确性也会从$68.3%$提升至$79.0%$</p>
<p>f. 另外的一些实验比较有:使用不同机器学习方法和调参算法的稳健性，predictability如何随time of the day变化，trades和quotes data的单独重要性，以及使用其它股票信息的用处。</p>
<h1 id="2-Response-and-Predictor-Variables"><a href="#2-Response-and-Predictor-Variables" class="headerlink" title="2. Response and Predictor Variables."></a>2. Response and Predictor Variables.</h1><h2 id="2-1-Transactions-and-Quotes-Data"><a href="#2-1-Transactions-and-Quotes-Data" class="headerlink" title="2.1 Transactions and Quotes Data"></a>2.1 Transactions and Quotes Data</h2><p>所使用的研究数据如下, trade data的order放下给是通过Lee and Ready(1991)的算法决定的，+1代表buy-initiated trade, -1代表sell-initiated trade. 然后trade data和quote data根据时间戳进行合并，并且只保留正常交易时段的数据.<br><img src="/images/hft_return/data.png" alt="data"><br>下表的上半部分代表了数据在daily level的统计值，下半部分代表了response variables的统计信息，同时，数据做了downsample来保证每天每只股票的数量大致相同。<br><img src="/images/hft_return/data_summary.png" alt="data summary"></p>
<h2 id="2-2-Response-Variables"><a href="#2-2-Response-Variables" class="headerlink" title="2.2 Response Variables."></a>2.2 Response Variables.</h2><p>作者首先定义了三种Clock，</p>
<ul>
<li>calendar clock: 就是原本时间戳</li>
<li>transcation clock: number of transcations have taken place.</li>
<li>volume clock: total volume transacted.<br> 看公式也比较好理解, Int代表Interval, 给定起始时间T，一个span $\Delta &gt; 0$,，和一个clock mode $M \in {calendar, transaction, volume}$, 其中span代表在各自clock mode下的衡量。<br><img src="/images/hft_return/clock.png" alt="clock"></li>
</ul>
<p>$\bm{D}^{txn}$表示所有对应trade data的时间戳，$\bm{D}^{qt}$为其quote上的对应部分，就是离第一个set中每个t最近的在quote data中的时间戳构成的集合。$\bm{D} &#x3D; \bm{D}^{txn} \cup \bm{D}^{qt}$， NBBO（National Best Bid and Offer prices）通过index $t \in \bm{D}$获取， best bid price: $P_t^b$, best ask price: $P_t^a$, mid price:$P_t &#x3D; \frac{P_t^a + P_t^b}{2}$, best bid size: $S_t^b$, best ask size: $S_t^a$, $P_t^{txn}$为transacted price如果$t\in \bm{D}^{txn}$.</p>
<h3 id="2-2-2-Transaction-return"><a href="#2-2-2-Transaction-return" class="headerlink" title="2.2.2 Transaction return"></a>2.2.2 Transaction return</h3><p>transaction return definition:<br><img src="/images/hft_return/transaction_return.png" alt="transaction return"><br>即为一个transaction span内的平均收益</p>
<h3 id="2-2-3-Price-direction"><a href="#2-2-3-Price-direction" class="headerlink" title="2.2.3 Price direction"></a>2.2.3 Price direction</h3><p><img src="/images/hft_return/direction.png" alt="direction"><br>其中$\bar{R}(\Delta, M)$代表过去transaction return的均值</p>
<h3 id="2-2-4-Transaction-duration"><a href="#2-2-4-Transaction-duration" class="headerlink" title="2.2.4 Transaction duration"></a>2.2.4 Transaction duration</h3><p><img src="/images/hft_return/duration.png" alt="duration"></p>
<p>这里定义的duration只有mode是transaction或是volume的时候才是有用的，预测duration对taker的execution schedule和maker撤单速度需求都有用</p>
<h2 id="2-3-Predictor-Variables"><a href="#2-3-Predictor-Variables" class="headerlink" title="2.3 Predictor Variables"></a>2.3 Predictor Variables</h2><p>这一节主要讲如何构建一些预测变量以及loock back window. 对前面提到的三种不同的mode, lookback interval分别可以定义为:<br><img src="/images/hft_return/lookback_int.png" alt="lookback_int"></p>
<table>
<thead>
<tr>
<th>Mode</th>
<th>lookback spans$(\Delta_1, \Delta_2)$</th>
</tr>
</thead>
<tbody><tr>
<td>Calendar</td>
<td>{(0,0.1), (0.1,0.2), (0.2,0.4), …, (12.8, 25.6)}</td>
</tr>
<tr>
<td>Transaction</td>
<td>{(0,1), (1,2), (2,4), …,(128,256)}</td>
</tr>
<tr>
<td>Volume</td>
<td>{(0,100), (100,200),(200,400),…,(12800,25600)}</td>
</tr>
</tbody></table>
<p>文中主要考虑了13个预测变量，可以划分为三大类，每个都在3个mode的9个lookback span下进行了实现:</p>
<h4 id="Volume-and-duration"><a href="#Volume-and-duration" class="headerlink" title="Volume and duration"></a>Volume and duration</h4><p><img src="/images/hft_return/volume_and_duration.png" alt="volume_and_duration"></p>
<h4 id="Return-and-imbalance"><a href="#Return-and-imbalance" class="headerlink" title="Return and imbalance"></a>Return and imbalance</h4><p><img src="/images/hft_return/return_and_imb.jpg" alt="return_and_imb"></p>
<h4 id="Speed-and-cost"><a href="#Speed-and-cost" class="headerlink" title="Speed and cost"></a>Speed and cost</h4><p><img src="/images/hft_return/speed_and_cost.png" alt="speed_and_cost"></p>
<h1 id="3-Machine-Learning-Methods"><a href="#3-Machine-Learning-Methods" class="headerlink" title="3.Machine Learning Methods"></a>3.Machine Learning Methods</h1><p>这一章主要介绍了用到的机器学习方法，主要有LASSO, RF, GBDT等，以及调参和衡量结果的metric。比较重要的是tuning, training, testing划分的方式：<br><img src="/images/hft_return/rolling_window.png" alt="rolling window"><br>基本是rolling window training的方式，但有一些细节的改变。假设有一个长度为40日的窗口，文中做法是先一分为二，划分为tuning period 20天，testing period 20天, tuning period中使用5天train, 5天test，总共有3份这样的数据，再根据在test上15天表现最好的超参选为后续5天train, 1天test的参数（图中黑线以下的示例），这样总共就有20天test的结果。结束后再把大的40天窗口roll forward 20天。</p>
<h1 id="4-Predictability-Results-for-Individual-Stocks"><a href="#4-Predictability-Results-for-Individual-Stocks" class="headerlink" title="4. Predictability Results for Individual Stocks."></a>4. Predictability Results for Individual Stocks.</h1><p>这里给出了S&amp;P 100支股票在2019-2020 505个交易日，使用117个变量（13 * 9 lookback spans）的结果。</p>
<h2 id="4-1-Transaction-Return-Prediction"><a href="#4-1-Transaction-Return-Prediction" class="headerlink" title="4.1 Transaction Return Prediction"></a>4.1 Transaction Return Prediction</h2><p><img src="/images/hft_return/4_1_return.png" alt="4_1_return"></p>
<p>图里给出了不同的target horizon的预测结果，每个box plot代表的都是平均的样本外$R^2$, 可以看到horizon越长结果越差，并且RF会比LASSO稍好。接下来使用5s的return分析比较重要的feature有: TxnImbalance和 PastReturn， 两者都是从transaction中得到的，同时能观察到比较有用的预测变量都是使用最近的数据，即lookback span为$(\Delta_1, \Delta_2) &#x3D; (0.0,0.1)$。另外一个启示可能是有时候trade和volume clock的return预测会比time return容易。</p>
<p><img src="/images/hft_return/lasso_magnitude.png" alt="Lasso variable"></p>
<p><img src="/images/hft_return/frequency_variable_group.png" alt="variable group"></p>
<p>这里也给出了预测不同的target每组预测变量被选中的频率，可以看到x轴后面几个gruop的预测变量经常被使用，但与Volume相关的频次就比较低。</p>
<h2 id="4-2-Price-Direction-Prediction"><a href="#4-2-Price-Direction-Prediction" class="headerlink" title="4.2 Price Direction Prediction"></a>4.2 Price Direction Prediction</h2><p><img src="/images/hft_return/direction_result.png" alt="direction prediction"><br>方向预测对较短的horizon，如5 seconds, 10 trade, 1000 shares，准确率是$64%$, 这里相比return预测有两点值得注意:LASSO和RF结果比骄接近、result更robust(更不分散)。</p>
<h2 id="4-3-Transaction-Duration-Prediction"><a href="#4-3-Transaction-Duration-Prediction" class="headerlink" title="4.3 Transaction Duration Prediction"></a>4.3 Transaction Duration Prediction</h2><p><img src="/images/hft_return/duration_result.png" alt="duration result"><br>这里做的是对成交数或成交量到达已经阈值所需时间的预测，与之前不同，这里预测的结果会随duration拉长而更准确，但是对预测更重要的feature变为了与volume相关的group。同时，duration prediction会使用所有group的feature，不像return预测时有很强的偏向性。<br><img src="/images/hft_return/duration_result_importance.png" alt="duration result imoprtance"></p>
<h2 id="4-4-Prediction-Consistency-Over-Time"><a href="#4-4-Prediction-Consistency-Over-Time" class="headerlink" title="4.4 Prediction Consistency Over Time"></a>4.4 Prediction Consistency Over Time</h2><p><img src="/images/hft_return/consistency.png" alt="consistency"></p>
<p>这一节给出了预测结果在时序上的表现，可预测性在时序上比较稳定，并且在Covid-19期间volatility的上升带来了显著的预测能力的下降。下一章更详细的研究了影响可预测性在截面和时序上差异的因素。</p>
<h1 id="5-Cross-Sectional-and-Time-Series-Determinants-of-Predictability"><a href="#5-Cross-Sectional-and-Time-Series-Determinants-of-Predictability" class="headerlink" title="5. Cross-Sectional and Time-Series Determinants of Predictability"></a>5. Cross-Sectional and Time-Series Determinants of Predictability</h1><h2 id="5-1-Nominal-Share-Price-Level-and-Price-Discreteness"><a href="#5-1-Nominal-Share-Price-Level-and-Price-Discreteness" class="headerlink" title="5.1 Nominal Share Price Level and Price Discreteness"></a>5.1 Nominal Share Price Level and Price Discreteness</h2><p>首先价格离散性会影响收益可预测性，简单理解就是股价越低，虽然最小变动单位是0.01，但报价一般都以5bps或者10bbps跳变，这就导致bid-ask spread会更大，这样便于估计买卖压力并更好预测短期回报和交易方向。下面的scatter plot也能反映nominal price和收益&#x2F;交易方向可预测性的负相关关系。但是，我们可以看到duration是与nominal price正相关的，可能解释是更大nominal price的股票liquidity更高，使得duration更好预期。</p>
<p><img src="/images/hft_return/nominal_price.png" alt="nominal price"></p>
<h2 id="5-2-Stock-Trading-Liquidity"><a href="#5-2-Stock-Trading-Liquidity" class="headerlink" title="5.2 Stock Trading Liquidity"></a>5.2 Stock Trading Liquidity</h2><p>这一节主要研究liquidity对个股收益的影响，作者用total traded dollar volume和percentage spread来衡量，图里结果反映了更好的liquidity（更高的volume或是更低的spread，使得收益和交易方向预测更难，但是duration变的更加容易预测。</p>
<p><img src="/images/hft_return/liquidity_scatter.png" alt="liquidity"></p>
<h2 id="5-3-Stock-Level-Volatility-and-Jumps"><a href="#5-3-Stock-Level-Volatility-and-Jumps" class="headerlink" title="5.3 Stock-Level Volatility and Jumps"></a>5.3 Stock-Level Volatility and Jumps</h2><p>volatility定义为一天内non-overlap的15s mid price return的std，jumps是一个binary dummies， 代表每天close-to-close的return是否在$3%-4%$, $4%-5%$以及大于$5%$的范围内，这里有panel regression的结果，结论是volatility对收益的可预测性有负向的影响，但是对duration的预测有帮助，jump同样是不利于收益预测，但有助于duration预测</p>
<h2 id="5-4-Asset-Pricing-Characteristics"><a href="#5-4-Asset-Pricing-Characteristics" class="headerlink" title="5.4 Asset Pricing Characteristics"></a>5.4 Asset Pricing Characteristics</h2><p>这一节检验了与index的beta，$R^2$，以及idiosyncratic volatilities对预测性的影响，idiosyncratic volatility定义为：</p>
<p>$$<br>Idiosyncratic\ Volatility &#x3D; \sqrt{1-Corr^2(\bm{R_x}, \bm{R_{SPY}})}SD(\bm{R_x})<br>$$</p>
<p>Panel regression结果显示beta和$R^2$与收益和方向的预测负相关，而idiosyncratic volatility和上一节中的结论基本一致。</p>
<h2 id="5-5-Market-Wide-Environment"><a href="#5-5-Market-Wide-Environment" class="headerlink" title="5.5 Market-Wide Environment"></a>5.5 Market-Wide Environment</h2><p>这一届检验市场情况和预测性的关系，market return用S&amp;P 500 close to close return表示，CBOE VIX用来表示market volatility，同样regression的结果显示市场volatility对收益和方向预测有反向效应，更大的市场波动使得一切更难预测。另外，当market return为正的时候相比大盘跌这些值更好预测，这个发现也与”leverage effect”相符。</p>
<h2 id="5-6-Multivariate-Stock-Level-Predictability"><a href="#5-6-Multivariate-Stock-Level-Predictability" class="headerlink" title="5.6 Multivariate Stock-Level Predictability"></a>5.6 Multivariate Stock-Level Predictability</h2><p>这里考虑以上提到的所有因素进行一个全面的多元panel regression分析，大多数解释变量的影响与之前的分析一致。总结：<strong>returns和trade direction对liquidity更小，less volatile，并且名义价更小，和市场相关性更低的股票是更好预测的</strong></p>
<p><img src="/images/hft_return/total_panel.png" alt="total panel"></p>
<h1 id="6-The-Value-of-a-Millisecond"><a href="#6-The-Value-of-a-Millisecond" class="headerlink" title="6. The Value of a Millisecond"></a>6. The Value of a Millisecond</h1><p>第6章回答了以下问题: 1. 过多久预测性会消失？ 2. 数据获取delay对预测性的影响？ 3. 如果能够进行非常简单的look ahead，可预测性是否会增加？</p>
<h2 id="6-1-The-Predictability-Lifespan"><a href="#6-1-The-Predictability-Lifespan" class="headerlink" title="6.1 The Predictability Lifespan"></a>6.1 The Predictability Lifespan</h2><p><strong>The predictability is very short lived.</strong> 对之前定义的三中clock，作者分别使用了Intel股票对应的horizons来检验第一个问题。下图中x代表不同的horizons，shaded area代表$95%$的置信区间。几乎所有的预测能力都会随着horizon拉长降低，returns只有在接下来3min，2000笔交易，500K volume之前是可以预测的。图中的plateau可能只是因为bias-variance trade off带来的，因为transaction更多的时候对平均收益的估计会更准确。</p>
<p><img src="/images/hft_return/horizon_disappear.png" alt="horizon disappear"></p>
<p>但对duration的在transaction clock下的预测来讲，在更长的horizon更容易预测因为horizon变长的时候transaction的数量会分布更均匀。在volume clock下更稳定并且逐渐降低。</p>
<p><img src="/images/hft_return/duration_horizon.png" alt="duration diminish"></p>
<h2 id="6-2-The-Impact-of-Delays-in-Acquiring-or-Processing-Data"><a href="#6-2-The-Impact-of-Delays-in-Acquiring-or-Processing-Data" class="headerlink" title="6.2 The Impact of Delays in Acquiring or Processing Data"></a>6.2 The Impact of Delays in Acquiring or Processing Data</h2><p><strong>Each millisecond is very valuable, or conversely every delay is costly.</strong> 这一节中引入一个delay $\delta$，来预测$R(T+\delta, \Delta, M)$，delay在不同的clock下有不同的含义，但是可预测性都会随着delay增加而显著降低。</p>
<p><img src="/images/hft_return/cost_delay.png" alt="cost delay"></p>
<h2 id="6-3-Peeking-into-the-Future"><a href="#6-3-Peeking-into-the-Future" class="headerlink" title="6.3 Peeking into the Future"></a>6.3 Peeking into the Future</h2><p>假设交易者能够提前获知一些order flow的信息，这种非完美的信息可能是因为有更深档的LOB数据，其他相关的securities或是futures的交易信息，或者是利用自己在其他交易所的quote反馈，与交易所更快的通讯等。</p>
<p><img src="/images/hft_return/bernoulli.png" alt="bernoulli"></p>
<p>通过引入这么一个包含未来信息，但是又受一个bernoulli分布影响的信息，p&#x3D;0.5时候完全代表一个noise。再将这个FlowDir与之前117个变量每一个交互将feature数量翻倍来进行预测。从结果来看，包含未来的transaction信息会将return的结果从14%提升到27%，ddirection的准确性从68%提升到79%，同时，随着信息减少(参数p增大)，效果也会衰减。<br><img src="/images/hft_return/peeking.png" alt="peeking"></p>
<h1 id="7-Robustness-Checks"><a href="#7-Robustness-Checks" class="headerlink" title="7. Robustness Checks"></a>7. Robustness Checks</h1><p>这一张主要是对整个流程和结果的robustness check。包括算法的选择，超参数的调节，单独使用transaction data或是quote data的影响，以及time of the day是否会造成可预测性的差异。</p>
<h2 id="7-1-Comparison-and-Consistency-of-Results-Across-Prediction-Methods"><a href="#7-1-Comparison-and-Consistency-of-Results-Across-Prediction-Methods" class="headerlink" title="7.1 Comparison and Consistency of Results Across Prediction Methods"></a>7.1 Comparison and Consistency of Results Across Prediction Methods</h2><p><img src="/images/hft_return/model_comparison.png" alt="model comparison"><br>从预测结果可以看到，所有的模型表现都比较接近，从LASSO到一些非线性模型的提升并不明显。OLS在一些test上表现不好可能是因为overfitting, 因为它的predictions很容易受noise影响，所以可能有几天产生了离ground truth很远的结果。</p>
<h2 id="7-2-Fine-tuning-the-Number-of-Trees-in-a-Random-Forest"><a href="#7-2-Fine-tuning-the-Number-of-Trees-in-a-Random-Forest" class="headerlink" title="7.2 Fine-tuning the Number of Trees in a Random Forest"></a>7.2 Fine-tuning the Number of Trees in a Random Forest</h2><p><img src="/images/hft_return/random_forest.png" alt="random forest"><br>random forests代表最基本的non-parametric method. 通过调节random forests中决策树的数量，可以看到对预测效果的提升是很小的。</p>
<h2 id="7-3-redictability-Using-Only-Subtypes-of-Data-Trades-vs-Quotes"><a href="#7-3-redictability-Using-Only-Subtypes-of-Data-Trades-vs-Quotes" class="headerlink" title="7.3 redictability Using Only Subtypes of Data: Trades vs. Quotes"></a>7.3 redictability Using Only Subtypes of Data: Trades vs. Quotes</h2><p>这一节通过只在每一个单独的data或者both的时间戳上计算出的预测变量来进行预测，结果表明在transaction-only的时间戳上得到的结果显著高于在quote-update only时间戳上的结果，这也与之前看到LASSO会给予从transaction得到特征更高权重的观察一致。这种现象的原因可能是由于两种数据时间戳时序分布的差异，也可能是transaction data噪音更少。<br><img src="/images/hft_return/different_data.png" alt="subtypes"></p>
<h2 id="7-4-Incremental-Predictability-Using-Additional-Data-From-Correlated-Stocks"><a href="#7-4-Incremental-Predictability-Using-Additional-Data-From-Correlated-Stocks" class="headerlink" title="7.4 Incremental Predictability Using Additional Data From Correlated Stocks"></a>7.4 Incremental Predictability Using Additional Data From Correlated Stocks</h2><p>相关股票的移动对预测要交易股票是有帮助的，这里选取了与Intel最相关的四只股票，来研究引入额外信息的影响。为了保持预测变量数量大体一致，这里每额外引入股票，都会降低lookback spans的数量。但是引入额外股票只带来了很小的提升，甚至30s return时还出现了$R^2$下降的情况。<br><img src="/images/hft_return/additional_stocks.png" alt="add stocks"></p>
<h2 id="7-5-Intraday-Seasonality-Predictability-Across-Different-Trading-Hours"><a href="#7-5-Intraday-Seasonality-Predictability-Across-Different-Trading-Hours" class="headerlink" title="7.5 Intraday Seasonality: Predictability Across Different Trading Hours"></a>7.5 Intraday Seasonality: Predictability Across Different Trading Hours</h2><p><img src="/images/hft_return/intraday.png" alt="imgs"><br>这里很有意思，研究了time of the day的影响。一般开闭盘的时候volatility会更高，中间会低一些，spreads一天内也会逐渐减小。文中先把一天化为9:30-10:00 opening session，10:00-15:30 midday session，15:30-16:00 closing session，再时序上只保留对应时段来做预测。结果显示<strong>return在一天之中相比开盘更好预测</strong>，<strong>可预测性在收盘之前最高</strong>，可能说明闭盘时候trading pattern更一致。</p>
<h1 id="8-Conclusion"><a href="#8-Conclusion" class="headerlink" title="8. Conclusion"></a>8. Conclusion</h1><ul>
<li>在ultra short频段上进行了三种预测，发现可预测性在股票中普遍存在。</li>
<li>liquid，volatility，nominal price，与市场相关性更小的securities更好预测，但更高的liquid和volatile会使得duration预测更容易。</li>
<li>可预测性消失很快，只集中在很短的窗口内，并且信息的delay或是ahead都会对预测结果有很大影响。</li>
<li>transaction data是最有价值的，调参和引入其他股票带来的结果提升不显著，intraday variability是值得被考虑的。</li>
</ul>
<p>Q：</p>
<ol>
<li>horizon should be matched with feature look back window</li>
<li>are different clocks can be combined with different sampling methods.</li>
<li>demean, de-market, use information from other stocks.</li>
<li>comparison of different models, the results?</li>
<li>stock demean?</li>
</ol>
]]></content>
      <categories>
        <category>Learn</category>
      </categories>
      <tags>
        <tag>quantitative finance</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Attentive Survival Analysis</title>
    <url>/2023/07/14/Deep_attentive/</url>
    <content><![CDATA[<h1 id="Deep-Attentive-Survival-Analysis-in-Limit-Order-Books-Estimating-Fill-Probabilities-with-Convolutional-Transformers"><a href="#Deep-Attentive-Survival-Analysis-in-Limit-Order-Books-Estimating-Fill-Probabilities-with-Convolutional-Transformers" class="headerlink" title="Deep Attentive Survival Analysis in Limit Order Books: Estimating Fill Probabilities with Convolutional-Transformers"></a>Deep Attentive Survival Analysis in Limit Order Books: Estimating Fill Probabilities with Convolutional-Transformers</h1><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>策略执行过程中一个重要的选择是在LOB上下passive(liquidity providing)还是aggressive(liquidity tkaing)的订单。回答这个问题需要知道在LOB上挂passive单的成交概率。本文提出了一种基于深度学习的方法来估计挂在LOB上不同挡位订单的成交概率。主要采用一种生存分析的方法俩将time varying的LOB特征映射到订单成交时间的分布上。方法主要使用convolutional-transformer的encode以及单调的神经网络decoder组成。作者使用<em>proper scoring rules</em>来将该方法与其他方法对比，并且探索了用来估计成交概率特征中蕴含的可解释性。最终，作者统计分析了挂在有着不同queue dynamics和trading activity的order book中不同位置订单的成交概率。</p>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>LOBs有不同的订单类型，其中limit orders和market orders最为常见。market orders会过spread在对手盘立刻成交，而limit orders会被放在订单簿不同挡位，如果成交的话会获得比market order更好的价格。limit order成交所需的时间被称为<strong>time-to-fill</strong>, 可以用不同方式估计。本文中，作者使用生存分析的方法来计算在LOB不同深度下limit orders的成交概率。</p>
<p>论文提出了从纵向数据中估计survival function的深度学习方法，具体利用一个基于transformer和部分单调的神经网络架构的encode-decoder结构。模型首先通过自注意力机制来总结在未下单前过去lookback window中最近的事件，然后利用这种潜在表示来估计订单提交后的成交概率。所使用的自注意力和卷积层提供了很有价值的时序信息，该信息可以提升基于最近trades对survival function的估计。为评估survival function的表现，作者采用<em>proper scoring function</em>来确保拟合正确。</p>
<p>论文主要使用Nasdaq交易所的数据。利用模型来预测挂在LOB不同档位订单的survival functions, 成交遵循price-time priority. 研究得到的结果在具有不同特征的资产上具有一致性。另外，作者通过shapley values发现模型主要依赖于高频信息，slow moving features提供的seasonal日内模式贡献较少。</p>
<h1 id="2-Literature-Review"><a href="#2-Literature-Review" class="headerlink" title="2. Literature Review"></a>2. Literature Review</h1><p>这部分就不展开啦，感兴趣的话可以到原文阅读</p>
<h1 id="3-Limit-Order-Books"><a href="#3-Limit-Order-Books" class="headerlink" title="3. Limit Order Books"></a>3. Limit Order Books</h1><p>挂单一直存在于LOB上知道被撮合成交或是扯淡。在文中，当提到market orders是，假设这些订单式要么是*fill-or-kill(FoK)<em>的订单，要么等待直到成交，要么被取消，或者是</em>immediate-or-cancel(IoC)<em>的市价单，要么被立刻成交(entirely or partially)在预先确定的价格范围内。另外，所有的订单都是</em>good for day(DAY)*的订单，当天收盘失效或是被撤单。</p>
<p>大部分交易所的撮合机制都遵循price-time priority，订单首先被按照价格排序，然后同一价位按照到达先后顺序。LOB有buy and ask双方，一个t时刻LOB的切片可以为被向量表示为：</p>
<p>$$<br>s_t&#x3D;\left{p_a^l(t), v_a^l(t), p_b^l(t), v_b^l(t)\right}_{l&#x3D;1}^L<br>$$<br>代表在时刻t ask和bid在不通过档位$l \in {1,…,L}$的量价。矩阵$\bm{x_t}\in \mathbb{R}^{T\times 4L}$代表LOB在时序t到t-T之间的变化。使用的message data的示例:<br><img src="/images/deep_attentive/image.png" alt="Example of message data"></p>
<h1 id="4-Survival-Analysis"><a href="#4-Survival-Analysis" class="headerlink" title="4. Survival Analysis"></a>4. Survival Analysis</h1><p><em>event time</em> $T_l\in\mathbb{R}<em>{\geq 0}$是一个随机变量，用来描述挂在不同档位$l$订单的成交时间。本文的目标是基于市场特征$\bm{x} \in \mathbb{R}^p$来预测$T_l$。所有的事件都是right-censoring的，即可能无法得到成交时间。当一个limit order被撤销，或是到达闭盘，就被考虑为一个censored event. 考虑N个形如$(\bm{x_i}, z_i, \delta_i)$的observations, $\delta_i$是一个indicator functions, 为0代表事件被censor， 其他情况为1. $z_i$和$\bm{x_i}$代表观测到的event time和截止挂单前最新的market features。 利用这个triplet可以估计survival function $S</em>{T_l}(t \mid \mathbf{x})&#x3D;\mathbb{P}\left{T_l&gt;t \mid \mathbf{x}\right}$</p>
<p><img src="/images/deep_attentive/image-1.png" alt="events after submission of a limit order"></p>
<p>survival function代表了挂在档位$l$订单在t时刻之前未被fill的概率。survival function 和对应的cumulative density function（CDF）之间的关系可以表示为:<br>$S_{T_l}(t \mid \mathbf{x})&#x3D;1 - F_{T_l}(t \mid \mathbf{x})$， 因此pdf: $f_{T_l}(t \mid \mathbf{x})&#x3D;- \frac{d}{dt} S_{T_l}(t \mid \mathbf{x})$描述了挂单之后在一定时间内成交的概率. 另外，<em>hazerd rate</em>表示订单在时间t后被成交的倾向性：<br>$$<br>h_{T_l}(t \mid \mathbf{x}) &#x3D; \frac{f_{T_l}(t \mid \mathbf{x}) }{ 1- F_{T_l}(t \mid \mathbf{x})}<br>$$<br>$S_{T_l}, F_{T_l}, h_{T_l}$之间有如下关系：<br>$$<br>S_{T_l}(t \mid \mathbf{x})&#x3D;\mathbb{P}\left{T_l&gt;t \mid \mathbf{x}\right}&#x3D;1-F_{T_l}(t \mid \mathbf{x})&#x3D;\exp \left(-\int_0^t h_{T_l}(s) d s\right)<br>$$</p>
<p>survival functions的形状有一组参数$\bm{\theta} \in \mathbb{R}$描述。一般可能认为该函数可以由一些分布近似(e.g. Weibull distribution)并估计相关的参数。另一种方式是要通过神经网络来近似survival functions，这样参数更多但能更好拟合数据并且能反映与市场特征之间的非线性关系。利用最大似然估计来最大化<em>right censored log-likelihood function</em>:<br>$$<br>\mathcal{L}(\boldsymbol{\theta})&#x3D;\log \left(L_N(\boldsymbol{\theta})\right)&#x3D;\sum_{k&#x3D;1}^N \delta_k \log \left(\hat{f}\left(z_k \mid \mathbf{x}_k, \boldsymbol{\theta}\right)\right)+\left(1-\delta_k\right) \log \left(\hat{S}\left(z_k \mid \mathbf{x}_k, \boldsymbol{\theta}\right)\right)<br>$$<br>$\hat{S}$和$\hat{f}$分别是neural network对survival function和density function的估计。具体的推导在appendix中。训练时，需要模型在精确的时间步来输出$\hat{S}(z_k | \bm{X_k}, \bm{\theta})$，本文使用的模型通过只对decoder输入时间$z_k$并结合从LOB中提取的latent representation, 从而在足够小的时间步上评估survival function并且遵循survival function的单调性。</p>
<p>为了评估模型拟合survival function的好坏，作者使用了<em>scoring rule</em>的概念。一个scoring rule$\mathcal{S}$的输入是一个在集合$\mathcal{Y}$上的分布$S$，观测样本$y \in \mathcal{Y}$, 并返回一个score $\mathcal{S}(S, y)$。对positive的scoring rules, 更高的分数代表模型你和更好，在生存回归中，一个scoring rule 是<em>proper</em>如果：<br>$$<br>\mathbb{E}<em>{t, c, \mathbf{x}}[\mathcal{S}(S(t \mid \mathbf{x}),(z, \delta))] \geq \mathbb{E}</em>{t, c, \mathbf{x}}[\mathcal{S}(\hat{S}(t \mid \mathbf{x}),(z, \delta))]<br>$$<br>对所有survival function的估计$\hat{S}(t \mid \mathbf{x})$, 即期望上，一个proper的scoring rule会给真实的survival function更高的分数。right-censored log-likelihood(RCLL)是一个proper scoring rule, 作者使用这个rule来确保你和的模型是正确逼近真实的survival function的。</p>
<h1 id="5-Empirical-and-Statistical-Evidence-of-Fill-Rate-Executions"><a href="#5-Empirical-and-Statistical-Evidence-of-Fill-Rate-Executions" class="headerlink" title="5. Empirical and Statistical Evidence of Fill Rate Executions"></a>5. Empirical and Statistical Evidence of Fill Rate Executions</h1><p>首先介绍两种得到limit orders的成交时间的方式，第一种是记录挂在LOB上的limit order的结果，第二种是利用虚拟订单来建模limit order repegging. 同时，也比较了第一种方式得到的survival function与不同order book档位的关联，以及第二种方式的top level的研究。</p>
<h2 id="5-1-Generating-of-training-data"><a href="#5-1-Generating-of-training-data" class="headerlink" title="5.1 Generating of training data"></a>5.1 Generating of training data</h2><p>第一种得到 ${(\bm{x_i}, z_i, \delta_i)}_{i&#x3D;1}^N$的方式是记录所有与某个订单挂单后有关的信息。如果最终成交，那么记录为filled, 不然记录为censored。time-to-fill在这里便指order submission后到观测到最终记录的时间。<br>另一种是利用虚假的订单，即放在交易队列末尾的一手订单。特别的，订单的survival function是与某档位的价格挂钩的，每次订单簿变动时都会检测该订单是否被fill。利用第二种方式，对订单簿中观测到的不同行为进行事后分析，文中只做了与LOB best ask and bid挂钩订单的分析。下图展示了估计的survival function随时间的变化,<br><img src="/images/deep_attentive/image-2.png" alt="order-repegging"></p>
<p>可以看到成交概率随时间降低，以及成交概率随着order repegging的增加，就是Level1比Level5更好成交。但是，这种visualization只提供了一个survival function平均的视角，并且不能捕捉订单成交概率的微观结构，因此作者提出基于DLd的方式。</p>
<h2 id="5-2-Fill-statisics-oflimit-orders-placed-inside-the-bid-ask-spread"><a href="#5-2-Fill-statisics-oflimit-orders-placed-inside-the-bid-ask-spread" class="headerlink" title="5.2 Fill statisics oflimit orders placed inside the bid-ask spread"></a>5.2 Fill statisics oflimit orders placed inside the bid-ask spread</h2><p>这里，计算了挂在spread里的订单的成交概率，结合tick和trading activity不同的股票进行分析，九支股票的具体信息如下图。</p>
<p><img src="/images/deep_attentive/image-6.png" alt="stock statistics"></p>
<p>直观上，交易tick较大的stock更倾向挂单在spread中，甚至跨过spread，但不能保证立刻成交，一个提升了best quotes的订单也更容易成交。这是合理的因为traders看到会立刻用liquidity taking的order match。</p>
<p><img src="/images/deep_attentive/image-3.png" alt="stocks survival"><br><img src="/images/deep_attentive/image-4.png" alt="sutvial analysis stocks"></p>
<p>结合上面两张图的结果可以得到：</p>
<ul>
<li>提升了best quotes的订单更容易成交，是合理的因为traders看到会立刻用liquidity taking的order match</li>
<li>大tick股票挂在spread中的成交概率在短时间内显著上升到与best quote接近，这说明如果订单几秒内被成交则价格会向有利方向移动，否则价格可能会反向移动，使得订单rest deeper</li>
<li>更活跃股票的survival function decay更快</li>
</ul>
<h1 id="6-Monotonic-Encoder-Decoder-Convolutional-Transformer"><a href="#6-Monotonic-Encoder-Decoder-Convolutional-Transformer" class="headerlink" title="6. Monotonic Encoder-Decoder Convolutional-Transformer"></a>6. Monotonic Encoder-Decoder Convolutional-Transformer</h1><h2 id="6-1-General-Architecture"><a href="#6-1-General-Architecture" class="headerlink" title="6.1 General Architecture"></a>6.1 General Architecture</h2><p>模型结构由两部分构成。encoder部分，参数$\Phi \in \mathbb{R}^{m_\Phi}$, 处理LOB数据并得到latent representation, 从而被decoder利用，参数为$\Psi \in \mathbb{R}^{m_\Psi+}$来预测limit order的survival function。decoder包含了一个单调的神经网络来保证是单调递减的survival function。encoder部分利用convolutional-transformer来建模LOB数据中复杂的依赖和影响关系。</p>
<p><img src="/images/deep_attentive/image-7.png" alt="conv-transformer models"></p>
<h2 id="6-2-Convolutional-Transformer-Encoder"><a href="#6-2-Convolutional-Transformer-Encoder" class="headerlink" title="6.2 Convolutional-Transformer Encoder"></a>6.2 Convolutional-Transformer Encoder</h2><p>encoder结构如下所示，处理LOB时序数据并捕捉non-Marokovian的动态关系，其中包括两部分：一个locally-aware的卷积网络和一个transfomer模型。locally-aware的网络包含3个不同的Dilated Causal Convolutional(DCC)neural network来处理LOB数据并产生对应的queries, keys和values。利用卷积网络的输出作为transfomer的Q,K,V使得encoder更能关注到local context, 是的transformer具备鉴别values是异常值还是某种模式。<br><img src="/images/deep_attentive/image-8.png" alt="Structure of conv-Transformer"></p>
<p>因此，DCCs的操作可以理解成一组数据驱动的local filters。从原始时间序列到卷积输出的hidden representation增强了对LOB的动态表述，从而transformer的自注意力机制也能捕捉到复杂的local依赖关系。另外，每一个DCCs的参数都是被调优用来从LOB中提取不同的相关特征。。比如，有些用来提取trend, 有些用来检测异常等。每个convolution neural network都有一层causal convolution构成，可以表示为：</p>
<p><img src="/images/deep_attentive/image-9.png" alt="qkv formula"></p>
<p>其中p是的dilation factor. 这里卷积网络主要是作为融入了local context的特征提取器，因此比较简单，appendix中也有增加卷积网络层数的实验结果。</p>
<p>cnvolutional-Transformer的优点在于卷积层使得模型locally-aware并且稀疏的self-attention缓解了空间复杂度，是的计算attention的复杂度从$O(L^2)$降低到$O(L(log(L))^2)$,  self-attention以及multi-head attention的原理就不介绍了。</p>
<h2 id="6-3-Monotonic-Decoder"><a href="#6-3-Monotonic-Decoder" class="headerlink" title="6.3 Monotonic Decoder"></a>6.3 Monotonic Decoder</h2><p>在生存分析中，survival function需要随着时间递减，作者在decoder中使用单调网络来保证这点。decoder的输出$f_\Phi(.)$与CDF的性质一致，因为满足：<br>$$<br>\text { (i) } \lim <em>{t \rightarrow-\infty} f</em>{\Psi}(t, \mathbf{x})&#x3D;0, \text { (ii) } \lim <em>{t \rightarrow \infty} f</em>{\Psi}(t, \mathbf{x})&#x3D;1, \text { (iii) } \frac{\partial f_{\Psi}(t, \mathbf{x})}{\partial t} \geq 0<br>$$<br>具体的细节appendix中有提供，但从下面这个图也可以直观理解，encoder这里会加入时间步t并保证其weight为正实数，最终再对得到的survival function求导。<br><img src="/images/deep_attentive/image-10.png" alt="monotonic decoder"></p>
<h1 id="7-Experiments"><a href="#7-Experiments" class="headerlink" title="7. Experiments"></a>7. Experiments</h1><h2 id="7-1-Predictive-Features"><a href="#7-1-Predictive-Features" class="headerlink" title="7.1 Predictive Features"></a>7.1 Predictive Features</h2><p>自变量分为<em>slow-moving</em>和<em>fast-moving</em>的, slow-moving features能提供日内的交易模式，其中一种是return的volatility，通常在开盘时候会比较高因为uncertainty和对overnight information的调整。同样的现象在交易量上也有体现，开收盘时会更高。fast-moving的features能够帮助更细粒度的预测，作者指出了几种可能比较重要的：bid-ask spread的未来演化，volatility, order arrival speed。最终使用的自变量有五档量价和volume imbalance, microprice这些。</p>
<h2 id="7-2-Model-Fit"><a href="#7-2-Model-Fit" class="headerlink" title="7.2 Model Fit"></a>7.2 Model Fit</h2><p>下面是很多实验结果，可以看到：</p>
<ul>
<li>提出的方法在RCLL评价指标下超过了benchmark models</li>
<li>考虑到time-varying dynamics的模型表现更好</li>
<li>convolutional-Transformer因为能更好的处理信息lookback window变长时效果也有提升， 但LSTM or CNN未观察到</li>
</ul>
<p><img src="/images/deep_attentive/image-11.png" alt="observed orders perform"></p>
<p><img src="/images/deep_attentive/image-12.png" alt="pegged orders dataset"></p>
<p><img src="/images/deep_attentive/image-13.png" alt="percentage improvement"></p>
<h1 id="7-3-Model-Interpretability"><a href="#7-3-Model-Interpretability" class="headerlink" title="7.3 Model Interpretability"></a>7.3 Model Interpretability</h1><p>作者主要利用attention heatmaps和shapley values来进行模型解释，从下图中不同head的attention map能看到，最左侧关注400 trades之前的volatility降低，其余的head有着稀疏的attention模式，表明模型结合了短期和长期信息来做出预测。<br><img src="/images/deep_attentive/image-14.png" alt="attention heatmaps"></p>
<p>shapley values的beeswarm plot主要画的是基本的MN-MLP模型的结果，虽然不是本文用到的复杂模型但能提供一些理解，能直接看到模型给了<em>fast-moving</em>的features更多的权重。</p>
<p><img src="/images/deep_attentive/image-15.png" alt="shapley values"></p>
<h1 id="8-Conclusions"><a href="#8-Conclusions" class="headerlink" title="8. Conclusions"></a>8. Conclusions</h1><p>本文结合convolutional-Transformer提出了一种估计limit order成交概率的方式。为训练和评估模型，使用了right-censored log-likelihood，是一种proper的scoring rule。模型在observed orders dataset和pegged orders dataset上均超越了基准模型。最终，借助Shapley values和attention heatmaps来对特征重要性做出评估。</p>
]]></content>
      <categories>
        <category>Learn</category>
      </categories>
      <tags>
        <tag>quantitative finance</tag>
      </tags>
  </entry>
  <entry>
    <title>Volatility Forecasting</title>
    <url>/2023/12/15/Volatility_Forecasting/</url>
    <content><![CDATA[<h1 id="Volatility-Forecasting-with-Machine-Learning-and-Intraday-Commonality"><a href="#Volatility-Forecasting-with-Machine-Learning-and-Intraday-Commonality" class="headerlink" title="Volatility Forecasting with Machine Learning and Intraday Commonality"></a>Volatility Forecasting with Machine Learning and Intraday Commonality</h1><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>本文主要基于机器学习模型探索股票的commnality对预测realized volatility(RV)的影响，结论表明neural networks表现超过linear &amp; tree-based models，该结论在直接用未出现在训练集里的股票测试时同样成立，这说明了股票之间共同的volatility mechanism。文中最后利用过去的日内波动率来预测未来一天的波动率，预测效果能够超过传统只用daily RVs的方式，并观察到了time-of-day效应对预测的影响。</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>HFT往往需要robust并且准确地预测日内波动率，Engle and Sokalska指出intraday volatility的预测对风险管理，衍生品定价，量化策略设计都有重要用途。但是学界缺少相关研究，大部分都是从日频收益出发，结果很难推广到日内。</p>
<p>本文利用美国S&amp;P 500指数中流动性最好的100支股票从2011年7月到2021年6月的高频数据，研究了non-parametric ML models在forecast multi-asset intraday volatility上的表现。首先提出了日内波动率commonality的衡量方式，实验结果说明commnality能够提升预测表现，同时NNs在样本外表现也超出linear &amp; tree-based models。当应用训练集未出现的股票做测试时，同样获得较好的结果，降低了对复杂模型过拟合风险的担忧。最后，日内波动率能为预测未来daily波动率提供额外信息。</p>
<h1 id="1-Related-Literature"><a href="#1-Related-Literature" class="headerlink" title="1. Related Literature"></a>1. Related Literature</h1><p>这里主要介绍了相关文献，第一部分是研究金融市场commonality，第二部分是预测daily波动率，但是预测日内波动率的关注较少，传统GARCH和SV 模型可能由于参数限制难以有效考虑金融变量间复杂且非线性的关系。第三，ML模型在金融领域潜力巨大，Bucci(2020)的研究表明RNNs在预测S&amp;P指数月度波动率方面能够超过传统计量经济的模型。</p>
<h1 id="2-Data-and-RV"><a href="#2-Data-and-RV" class="headerlink" title="2. Data and RV"></a>2. Data and RV</h1><p>数据使用从2011-07-01到2021-06-30 S&amp;P index Top 100成分股的高频数据，筛选掉没有横跨整个周期的股票，剩余93支，板块分类如下：<br><img src="/images/vol_forecast/image.png" alt="Alt text1"></p>
<p>$P_{i,t}$代表金融资产i的价格过程如下，$\mu_i$代表drift, $\sigma_{i,t}$代表顺势波动率，$W_t$是标准布朗运动</p>
<p>$$<br>dlogP_{i,t} &#x3D; \mu_idt + \sigma_{i,t}dW_t<br>$$</p>
<p>股票i在(t-b, t]之间的theoretical integrated variance表示为:<br>$$<br>IV_{i,t}(b) &#x3D; \int_{t-b}^{t}\sigma_{i,s}^2 ds<br>$$<br>b代表回看长度，如10min, 30min, 1天。每分钟的中间价对数收益为：</p>
<p>$$<br>r_{i,t}:&#x3D;log(\frac{P_{i,t}}{P_{i,t-1}})<br>$$</p>
<p>日内收益的平方和是IV的一致估计量，RV可以被当作IV的proxy，在(t-b, t]之间，RV被定义为：</p>
<p>$$<br>RV_{i,t}^{(b)} :&#x3D; log[\sum_{s&#x3D;t-b+1}^t r_{i,s}^2]<br>$$</p>
<p>overnight的信息不再考虑范围内。</p>
<p>数据处理部分对收益做了0.5%的winsorize。下图可以看到整个样本里在不同回看周期上pairwise correlation的直方图，具体计算方式应该是每两只股票的RV或者return计算一个correlation，然后看整体数值，也就是$C_{93}^2$个数据点的分布，比较有趣的是日内随着b（回看窗口）的拉长，RV相关性实际会先上升，但到1-day又会降低，这说明股票间日内波动率的关联可能比daily波动率更稳定。<br><img src="/images/vol_forecast/image-1.png" alt="Alt text2"></p>
<p>Figure2可以看到股票之间整体的daily RV的时序变化，两边quantile的弥散度在欧洲主权债务危机，中国股灾，英国脱欧，中美贸易战和COVID-19期间都明显紧缩，Figure 3可以看到30min RV在一天内形成的rever-J-shape.<br><img src="/images/vol_forecast/image-2.png" alt="Alt text3"><br><img src="/images/vol_forecast/image-3.png" alt="Alt text4"></p>
<h1 id="3-Commonality-Estimation"><a href="#3-Commonality-Estimation" class="headerlink" title="3. Commonality Estimation"></a>3. Commonality Estimation</h1><p>这部分主要讲如何估计股票之间的commonality，主要利用如下回归的adjust $R^2$作为波动率commonality的衡量，其中$\mathrm{RV}_{M, t}^{(b)}$代表t时刻根据单个股票加权计算的市场波动率:</p>
<p>$$<br>\mathrm{RV}<em>{M, t}^{(b)}&#x3D;\frac{1}{N} \sum</em>{i&#x3D;1}^N \mathrm{RV}<em>{i, t}^{(b)},\qquad \mathrm{RV}</em>{i, t}^{(b)}&#x3D;\alpha_i+\beta_i \mathrm{RV}<em>{M, t}^{(b)}+\epsilon</em>{i, t}<br>$$</p>
<p>每月进行一次回归并在股票之间取平均，可以从Figure4看到日内的commonality现象是要比daily的更显著且稳定的。Figure5中展示了在交易时段每半个小时的commonality的均值和标准差，与之前波动率的J-curve不同，这里接近收盘commonality会逐渐上升。</p>
<p><img src="/images/vol_forecast/image-4.png" alt="Alt text5"><br><img src="/images/vol_forecast/image-5.png" alt="Alt text6"></p>
<h1 id="4-Methodology"><a href="#4-Methodology" class="headerlink" title="4. Methodology"></a>4. Methodology</h1><p>本节尝试利用股票之间的commonality来预测跨资产的波动率，整体模型可以表示为：<br>$$<br>\begin{aligned}<br>\mathrm{RV}<em>{i, t+b}^{(b)} &amp; &#x3D;F_i(\mathbf{u} ; \theta)+\epsilon</em>{i, t+b} \<br>&amp; &#x3D;F_i\left(\mathrm{RV}<em>{i, t}^{(b)}, \ldots, \mathrm{RV}</em>{i, t-(p-1) b}^{(b)}, \mathrm{RV}<em>{M, t}^{(b)}, \ldots, \mathrm{RV}</em>{M, t-(p-1) b}^{(b)} ; \theta\right)+\epsilon_{i, t+b}<br>\end{aligned}<br>$$<br>注意这里$\mathrm{RV}_{i, t+b}^{(b)}$代表的是未来波动率。输入特征包含两部分，首先是individual features，包含单个股票截止t已知的信息，另外是market features，聚合了所有股票包含t时刻已知的信息，$\theta$代表模型参数。模型的细节这里就不赘述了，基本介绍了Seasonal ARIMA, HAR with diurnal effects, OLS, Lasso&#x2F;Ridge, XGBoost, MLP以及LSTM。model训练部分会有三种方式，逐渐向其中加入cross asset和market information:</p>
<ol>
<li>Single: 只使用股票i的过去RVs作为特征</li>
<li>Universal: 股票i还是只是本身特征，但是所有股票的数据放在一起训练</li>
<li>Augmented: 股票i使用individual and market features，同样股票放在一起训练</li>
</ol>
<p>评价指标使用：</p>
<ul>
<li><p>Mean - squarederror (MSE): $\frac{1}{N} \sum_{i&#x3D;1}^N \frac{1}{T_{\text {test }}} \sum_{t \in \mathcal{T}<em>{\text {test }}}\left(\mathrm{RV}</em>{i, t}^{(b)}-\widehat{\mathrm{RV}}_{i, t}^{(b)}\right)^2$,</p>
</li>
<li><p>Quasi - likelihood (QLIKE): $\frac{1}{N} \sum_{i&#x3D;1}^N \frac{1}{T_{\text {trst }}} \sum_{t \in \mathcal{T}<em>{\text {test }}}\left[\frac{\exp \left(\mathrm{RV}</em>{i, t}^{(b)}\right)}{\exp \left(\widehat{\mathrm{RV}}<em>{i, t}^{(b)}\right)}-\left(\mathrm{RV}</em>{i, t}^{(b)}-\widehat{\mathrm{RV}}_{i, t}^{(b)}\right)-1\right]$</p>
</li>
</ul>
<h1 id="5-Experiments"><a href="#5-Experiments" class="headerlink" title="5. Experiments"></a>5. Experiments</h1><p>数据集会被划分为: training, validation, testing，采用roll forward的方式，一年做validation, 一年testing，前面的日期都作为training。 MLP &amp; NNs会采用ensemble的方式，即在不同的初始化条件下训练多个模型后做平均。</p>
<p><img src="/images/vol_forecast/image-6.png" alt="Alt text7"></p>
<p>实验结果如上表所示，可以看到LSTM能够在日内表现最好，并且有着最高的realized utility。但是能看到，在1-day的时候,LASSO表现最好，这可能是因为数据稀缺性导致的(相比日内)。Figure 7中展示了不同trading shcema下QLIKEs的差值，即$\Delta QLIKE$, 该数值越负代表out of sample表现的提升，可以看到Universal相比Single的提升其实并不名贡献，但是加入市场的信息后提高了预测表现。</p>
<p><img src="/images/vol_forecast/image-7.png" alt="Alt text8"></p>
<p>另外一个值得思考的问题是Universal或Augmented setting的提升是否与股票的commonality有联系。从Figure8可以看到，样本外的QLIKE是会随着股票commonality的提升而下降的。<br><img src="/images/vol_forecast/image-8.png" alt="Alt text9"></p>
<p>为了测试拟合模型的generalization能力，可以使用训练集里未出现的股票来测试模型，记录模型使用的股票为raw stocks, 新的测试股票为unseen stocks, Figure 9展示了得到的结果，能够得出结论，在聚合的股票池上训练出的NN模型有更好的预测能力，为股票间的<em>universal volatility mechanism</em>提供了证据。</p>
<p><img src="/images/vol_forecast/image-9.png" alt="Alt text10"></p>
<h1 id="6-Forecasting-Daily-RVs-with-Intraday-RVs"><a href="#6-Forecasting-Daily-RVs-with-Intraday-RVs" class="headerlink" title="6. Forecasting Daily RVs with Intraday RVs"></a>6. Forecasting Daily RVs with Intraday RVs</h1><p>从前述实验可以看到预测日内波动率时股票之间commonality的作用，这里对利用日内波动率来预测未来的daily波动率进行研究，介绍了<em>Intraday2Daily</em>的方式，模型为：</p>
<p>$$<br>\mathrm{RV}<em>{i, t+1}^{(d)}&#x3D;F_i\left(\mathrm{RV}</em>{i, t}^{(b)}, \ldots, \mathrm{RV}<em>{i, t-(p-1) b}^{(b)}, \mathrm{RV}</em>{i, t-1}^{(d)}, \ldots, \mathrm{RV}<em>{i, t-(p-1)}^{(d)} ; \theta\right)+\epsilon</em>{i, t+1}<br>$$<br>这里，前半部分$\left(\mathrm{RV}<em>{i, t}^{(b)}, \ldots, \mathrm{RV}</em>{i, t-(k-1) b}^{(b)}\right)$代表股票i在日内horizon b上的波动率，后半部分$\left(\mathrm{RV}<em>{i, t-1}^{(d)}, \ldots, \mathrm{RV}</em>{i, t-(p-1)}^{(d)}\right)$代表过去daily RVs，但是只截止到t-1天，相当于用t天的日内波动率和t-1之前的daily RVs来预测未来RVs。</p>
<p><img src="/images/vol_forecast/image-10.png" alt="Alt text11"></p>
<p><img src="/images/vol_forecast/image-11.png" alt="Alt text12"></p>
<p>与之前的实验结果相比，这种方式能够提升基准模型的表现，使用了日间信息的MLP模型达到了最好的表现，同时也达到了更高的utilities。最后，这里还研究了time-of-day的现象，使用上述实验最近一天OLS model intraday RV的系数进行比较，可以看到，接近收盘的波动率时最重要的指标，而非白天的波动模式。有数据表明收盘半小时会占据美国市场3000支股票2020年前几个月约23%的交易量，这也使得收盘前的波动率成为预测下一日波动率的重要信息。<br><img src="/images/vol_forecast/image-12.png" alt="Alt text13"></p>
<p>这篇文章对股票的commonality进行了详细研究，并且比较了不同模型和setting下的表现， NN因为能够捕捉predictors之间的复杂关系而有着更好的表现，同时训练出的模型也展示出了一定的泛化能力，即在未见过的股票上进行预测。最后，利用日内波动率预测daily RVs有一定效果，同时也能观察到收盘前波动率的重要性。受限于篇幅，很多细节没有展开，大家感兴趣可以参考原文。</p>
]]></content>
      <categories>
        <category>Learn</category>
      </categories>
      <tags>
        <tag>quantitative finance</tag>
      </tags>
  </entry>
</search>
